WebScraping:
-Extracting the data from a web page and storing it as structured data in an csv file or sql gile
-Parse/filter unnecessary data, so you create the data and store it in the data file.

Exteraction phase:you give python the url of the website, next python scans the page source to get the html code and extract the content of a specific html tag

Parse/filter phase: we extract specific filtered information and store it into a file.

# the header is used to tell the webserver that this script is a browser, since some websites doesn't like or allow scripts
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}

To extract data we use selectorlib and Extractor class with function from_yaml_file("file.yaml")
and for that we need to create a yaml file.